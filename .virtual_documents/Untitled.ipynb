import pandas as pd
import numpy as np



data = pd.read_csv('./data/adult.csv')
data.head()


data['income'].value_counts(normalize = True)


data['income'] = np.where(data['income'] == '>50K', 'high', 'low')
data['income'].value_counts(normalize = True)


data = data.drop(columns = 'fnlwgt')


data.info()


data_tmp = data[['sex']]
data_tmp.info()


data_tmp['sex'].value_counts()


data_tmp = pd.get_dummies(data_tmp)
data_tmp.info()


data_tmp[['sex_Female', 'sex_Male']].head()


target = data['income']
data = data.drop(columns = 'income')
data = pd.get_dummies(data)

data['income'] = target
data.info()


data.info(max_cols = np.inf)


from sklearn.model_selection import train_test_split
from sklearn import tree


df_train, df_test = train_test_split(data, 
                                    test_size = 0.3,
                                    stratify = data['income'],
                                    random_state = 1234)


df_train.shape, df_test.shape


clf = tree.DecisionTreeClassifier(random_state = 1234, max_depth = 3)


train_x = df_train.drop(columns = 'income')
train_y = df_train['income']
model = clf.fit(X = train_x, y = train_y)


import matplotlib.pyplot as plt
plt.rcParams.update({'figure.figsize' : [12, 8], 'figure.dpi' : '100'})
tree.plot_tree(model,
              feature_names = train_x.columns,
              class_names = ['high', 'low'],
              proportion = True,
              filled = True,
              rounded = True,
              impurity = False,
              label = 'root',
              fontsize = 10);


test_x = df_test.drop(columns = 'income')
test_y = df_test['income']


df_test['pred']= model.predict(test_x)
df_test


from sklearn.metrics import confusion_matrix
conf_mat = confusion_matrix(y_true = df_test['income'],
                           y_pred = df_test['pred'],
                           labels = ['high', 'low'])

conf_mat


plt.rcParams.update(plt.rcParamsDefault)
from sklearn.metrics import ConfusionMatrixDisplay
p = ConfusionMatrixDisplay(confusion_matrix = conf_mat,
                          display_labels = ('high', 'low'))
p.plot(cmap = 'Blues')
plt.show()


import sklearn.metrics as metrics


metrics.accuracy_score(y_true = df_test['income'],
                      y_pred = df_test['pred'])


metrics.precision_score(y_true = df_test['income'],
                       y_pred = df_test['pred'],
                       pos_label = 'high')


#F1 score
#recall 과 precision이 모두 중요할 때 recall과 precision의 크기를 함께 반영한 F1 score를 사용한다
# F1 score은 recall 과 precision의 조화평균으로 0~1사이의 값


metrics.f1_score(y_true = df_test['income'],
                y_pred = df_test['pred'],
                pos_label = 'high')



